{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hjMTJl5fSAyY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-16 15:19:23.127587: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-10-16 15:19:23.515701: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-16 15:19:25.430322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XSMI5KdOSgSN"
      },
      "outputs": [],
      "source": [
        "class DenseNN(tf.Module):\n",
        "    def __init__(self, outputs, activate=\"relu\"):\n",
        "        super().__init__()\n",
        "        self.outputs = outputs\n",
        "        self.activate = activate\n",
        "        self.fl_init = False\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if not self.fl_init:\n",
        "            self.w = tf.random.truncated_normal((x.shape[-1], self.outputs), stddev=0.1, name=\"w\")\n",
        "            self.b = tf.zeros([self.outputs], dtype=tf.float32, name=\"b\")\n",
        "\n",
        "            self.w = tf.Variable(self.w)\n",
        "            self.b = tf.Variable(self.b)\n",
        "\n",
        "            self.fl_init = True\n",
        "\n",
        "        y = x @ self.w + self.b\n",
        "\n",
        "        if self.activate == \"relu\":\n",
        "            return tf.nn.relu(y)\n",
        "        elif self.activate == \"softmax\":\n",
        "            return tf.nn.softmax(y)\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ODenl1_ySjrI"
      },
      "outputs": [],
      "source": [
        "class Sm(tf.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l_1 = DenseNN(128)\n",
        "        self.l_2 = DenseNN(10, activate = 'softmax')\n",
        "    def __call__(self, x):\n",
        "        return self.l_2(self.l_1(x))\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTRaCFcYT5kd",
        "outputId": "60705d09-116b-40ca-f8a2-f3ec2f7b767d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-16 15:19:42.795948: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-16 15:19:43.146385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-16 15:19:43.146454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-16 15:19:43.180455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-16 15:19:43.180531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-16 15:19:43.180544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-16 15:19:45.779562: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-16 15:19:45.780510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-16 15:19:45.780545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2023-10-16 15:19:45.780571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-10-16 15:19:45.780649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1592 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "x_train = tf.reshape(tf.cast(x_train, tf.float32), [-1, 28*28])\n",
        "x_test = tf.reshape(tf.cast(x_test, tf.float32), [-1, 28*28])\n",
        "\n",
        "y_train = to_categorical(y_train, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfM9HfurTQ_0",
        "outputId": "c71293c2-ccc6-4bf7-8130-3aef6d886f81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<__main__.Sm object at 0x7f21e980be50>\n"
          ]
        }
      ],
      "source": [
        "model = Sm()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tsDQG40-TZKe"
      },
      "outputs": [],
      "source": [
        "cross_entropy = lambda y_true, y_pred: tf.reduce_mean(tf.losses.categorical_crossentropy(y_true, y_pred))\n",
        "opt = tf.optimizers.Adam(learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "y6zsTO20Tyoc"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "TOTAL = x_train.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "inG3sNDzT28p"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTZ6TdnzUBn4",
        "outputId": "4336834a-5086-4673-9cb4-6da9b9be463e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 75001 calls to <function _BaseOptimizer._update_step_xla at 0x7f220fd5d9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "loss = 503.3775634765625\n",
            "loss = 222.39439392089844\n",
            "loss = 152.7122039794922\n",
            "loss = 112.2451171875\n",
            "loss = 87.28946685791016\n",
            "loss = 66.24317169189453\n",
            "loss = 51.58202362060547\n",
            "loss = 40.854087829589844\n",
            "loss = 33.673946380615234\n",
            "loss = 27.639829635620117\n",
            "loss = 23.12002182006836\n",
            "loss = 22.661636352539062\n",
            "loss = 17.314647674560547\n",
            "loss = 15.803730964660645\n",
            "loss = 12.719385147094727\n",
            "loss = 13.536865234375\n",
            "loss = 13.01051139831543\n",
            "loss = 10.643952369689941\n",
            "loss = 9.269742965698242\n",
            "loss = 9.6825532913208\n"
          ]
        }
      ],
      "source": [
        "for n in range(EPOCHS):\n",
        "    loss = 0\n",
        "\n",
        "    for x_batch, y_batch in train_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            f_loss = cross_entropy(y_batch, model(x_batch))\n",
        "\n",
        "        loss += f_loss\n",
        "        grads = tape.gradient(f_loss, model.trainable_variables)\n",
        "        opt.build(model.trainable_variables)\n",
        "        opt.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    print(f'loss = {loss.numpy()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Qr3oR-UEMo",
        "outputId": "9fd8f3e6-e214-40df-c8d5-6c29a033e0c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 98.03000092506409\n"
          ]
        }
      ],
      "source": [
        "y = model(x_test)\n",
        "y_pred = tf.argmax(y, axis=1).numpy()\n",
        "acc = tf.metrics.Accuracy()\n",
        "acc.update_state(y_test, y_pred)\n",
        "print(f'Accuracy = {acc.result().numpy()*100}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MTtmzr_veNsU"
      },
      "outputs": [],
      "source": [
        "def start_count(arr):\n",
        "    result = np.zeros(10)\n",
        "    for i in range(len(arr)):\n",
        "        path = os.path.join('photos', arr[i])\n",
        "        image = tf.keras.utils.load_img(path)\n",
        "        image = tf.image.resize(image, (28, 28))\n",
        "        image = tf.image.rgb_to_grayscale(image)\n",
        "        image = tf.squeeze(image, axis=2)\n",
        "        image = image.numpy()\n",
        "        prediction = model(image.reshape(1, 28*28))\n",
        "        prediction = tf.argmax(prediction, axis=1)\n",
        "        result[int(prediction)-1]+=1\n",
        "        if i%500==0:\n",
        "            print(f'i = {i}, result = {result}')\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i = 0, result = [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "i = 500, result = [66. 40. 54. 62. 53. 52. 32. 41. 43. 58.]\n",
            "i = 1000, result = [143.  83. 108. 108. 113. 105.  66.  72.  88. 115.]\n",
            "i = 1500, result = [208. 131. 159. 161. 158. 158. 106. 110. 149. 161.]\n",
            "i = 2000, result = [256. 183. 231. 217. 219. 208. 140. 145. 189. 213.]\n",
            "i = 2500, result = [322. 226. 298. 263. 256. 258. 178. 191. 235. 274.]\n",
            "i = 3000, result = [381. 272. 365. 315. 301. 308. 224. 233. 273. 329.]\n",
            "i = 3500, result = [446. 317. 420. 370. 350. 359. 253. 276. 323. 387.]\n",
            "i = 4000, result = [503. 356. 482. 427. 405. 423. 287. 315. 379. 424.]\n",
            "i = 4500, result = [566. 400. 551. 488. 457. 465. 316. 344. 421. 493.]\n",
            "i = 5000, result = [637. 449. 605. 540. 499. 519. 353. 382. 474. 543.]\n",
            "i = 5500, result = [701. 502. 661. 596. 555. 564. 385. 427. 515. 595.]\n",
            "i = 6000, result = [756. 535. 742. 661. 602. 611. 419. 454. 568. 653.]\n",
            "i = 6500, result = [822. 590. 799. 723. 646. 659. 456. 490. 613. 703.]\n",
            "i = 7000, result = [895. 637. 859. 768. 685. 710. 504. 523. 666. 754.]\n",
            "i = 7500, result = [962. 697. 919. 818. 734. 747. 551. 557. 728. 788.]\n",
            "i = 8000, result = [1014.  737.  978.  880.  779.  794.  591.  595.  786.  847.]\n",
            "i = 8500, result = [1080.  784. 1030.  941.  827.  843.  622.  641.  834.  899.]\n",
            "i = 9000, result = [1127.  826. 1099.  994.  888.  887.  653.  682.  889.  956.]\n",
            "i = 9500, result = [1185.  870. 1147. 1054.  941.  925.  693.  726.  942. 1018.]\n",
            "i = 10000, result = [1257.  913. 1201. 1107.  984.  986.  734.  760.  987. 1072.]\n",
            "i = 10500, result = [1323.  958. 1250. 1154. 1045. 1043.  768.  803. 1029. 1128.]\n",
            "i = 11000, result = [1387.  997. 1313. 1209. 1097. 1099.  805.  854. 1067. 1173.]\n",
            "i = 11500, result = [1444. 1056. 1365. 1266. 1146. 1144.  847.  896. 1114. 1223.]\n",
            "result = [1523. 1096. 1421. 1324. 1187. 1192.  885.  928. 1161. 1283.]\n"
          ]
        }
      ],
      "source": [
        "arr = os.listdir('photos')\n",
        "# len(arr)\n",
        "result = start_count(arr)\n",
        "print(f'result = {result}')\n",
        "# result = [1537. 1142. 1470. 1367. 1196. 1097.  907.  854. 1196. 1234.] 10 epochs\n",
        "# result = [1523. 1096. 1421. 1324. 1187. 1192.  885.  928. 1161. 1283.] 20 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def show_image(x):\n",
        "    image = tf.keras.utils.load_img(f'photos/{x}')\n",
        "    image = tf.image.resize(image, (28, 28))\n",
        "    image = tf.image.rgb_to_grayscale(image)\n",
        "    image = tf.squeeze(image, axis=2)\n",
        "    x = image.numpy()\n",
        "    prediction = model(x.reshape(1, 28*28))\n",
        "    print(np.argmax(prediction))\n",
        "    plt.imshow(image, cmap='binary')\n",
        "    # print(image.shape)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_image(arr[99])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7]\n",
            "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7]\n"
          ]
        }
      ],
      "source": [
        "pred_test = model(x_test)\n",
        "pred_test = np.argmax(pred_test, axis=1)\n",
        "\n",
        "# print(pred_test.shape)\n",
        "\n",
        "print(pred_test[:35])\n",
        "print(np.argmax(y[:35], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 971,    0,    2,    0,    0,    0,    4,    1,    1,    1],\n",
              "       [   0, 1127,    2,    0,    0,    0,    2,    1,    3,    0],\n",
              "       [   5,    1, 1014,    2,    1,    0,    3,    3,    3,    0],\n",
              "       [   0,    0,    3,  986,    1,    6,    0,    5,    4,    5],\n",
              "       [   2,    0,    3,    0,  963,    1,    3,    1,    1,    8],\n",
              "       [   2,    0,    0,    7,    1,  874,    3,    0,    4,    1],\n",
              "       [   4,    3,    4,    1,    2,    8,  935,    0,    1,    0],\n",
              "       [   2,    4,   11,    0,    1,    0,    0, 1002,    1,    7],\n",
              "       [   2,    1,    5,    4,    4,    6,    1,    4,  943,    4],\n",
              "       [   3,    2,    2,    1,    6,    3,    0,    2,    2,  988]])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_pred=pred_test, y_true=y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
